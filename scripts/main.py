from dotenv import load_dotenv
import os
import pandas as pd
from src.data.faiss_loader import load_faiss_index
from src.rag.retriever import CustomRetriever
from src.chain.qa_chain import build_qa_chain
from langchain_community.embeddings import OpenAIEmbeddings

load_dotenv()

PARQUET_PATH = os.getenv("PARQUET_PATH")
FAISS_INDEX_PATH = os.getenv("FAISS_INDEX_PATH")
ID_MAPPING_PATH = os.getenv("ID_MAPPING_PATH")

df = pd.read_parquet(PARQUET_PATH)
faiss_index, id_mapping = load_faiss_index(FAISS_INDEX_PATH, ID_MAPPING_PATH)
embeddings = OpenAIEmbeddings()

retriever = CustomRetriever(
    embeddings=embeddings,
    faiss_index=faiss_index,
    id_mapping=id_mapping,
    documents_df=df,
)

qa_chain = build_qa_chain(retriever)

print("\nüìò LegalQA k√©rdezz-felelek. √çrd be a k√©rd√©sed, vagy 'exit'-tel kil√©phetsz.")
chat_history = []

while True:
    question = input("\n‚ùì K√©rd√©s: ")
    if question.strip().lower() == ["exit", "quit"]:
        break
    
    result = qa_chain.invoke({
        "question": question,
        "chat_history": chat_history
        })
    
    print(f"\nüßæ V√°lasz:\n{result['answer']}")
    chat_history.append((question, result["answer"]))