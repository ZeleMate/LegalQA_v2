{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Chain Test with Current Architecture\n",
    "\n",
    "Ez a notebook a jelenlegi RAG pipeline-t teszteli lokális sample adatokkal. Az aktuális architektúrával kompatibilis:\n",
    "- **Google Gemini** embeddings és LLM\n",
    "- **Custom és Reranking Retriever** implementáció  \n",
    "- **Lokális FAISS index** és DataFrame-ek\n",
    "\n",
    "**Setup:** \n",
    "1. `conda activate legalqa`\n",
    "2. `python scripts/create_sample.py`\n",
    "3. `python scripts/build_local_index.py`\n",
    "4. Állítsd be a `.env` fájlt a `GOOGLE_API_KEY`-jel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zelenyianszkimate/miniforge3/envs/legalqa/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/Users/zelenyianszkimate/miniforge3/envs/legalqa/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports completed!\n",
      "📁 Working directory: /Users/zelenyianszkimate/Documents/LegalQA_v2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import asyncio\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Any\n",
    "import textwrap\n",
    "\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import current architecture components\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from pydantic import SecretStr\n",
    "\n",
    "# Import our current components\n",
    "from src.chain.qa_chain import build_qa_chain\n",
    "from src.data_loading.faiss_loader import load_faiss_index\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Change to project root if needed\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "print(\"✅ Imports completed!\")\n",
    "print(f\"📁 Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Loading sample data with current architecture...\n",
      "📊 Loading sample data from: data/processed/sample_data.parquet\n",
      "🔍 Loading FAISS index from: data/processed/sample_faiss.bin\n",
      "✅ Data loaded successfully!\n",
      "  📄 Documents: 8293\n",
      "  🔍 FAISS vectors: 8293\n",
      "  🗂️ ID mappings: 8293\n",
      "🤖 Google Gemini embeddings initialized!\n"
     ]
    }
   ],
   "source": [
    "# Load sample data using current architecture\n",
    "print(\"🔧 Loading sample data with current architecture...\")\n",
    "\n",
    "# Get paths for sample data (same as build_local_index.py)\n",
    "sample_parquet_path = os.getenv(\"NOTEBOOK_PARQUET_PATH\", \"data/processed/sample_data.parquet\")\n",
    "faiss_index_path = os.getenv(\"NOTEBOOK_FAISS_PATH\", \"data/processed/sample_faiss.bin\") \n",
    "id_mapping_path = os.getenv(\"NOTEBOOK_ID_MAPPING_PATH\", \"data/processed/sample_mapping.pkl\")\n",
    "\n",
    "# Verify files exist\n",
    "required_files = [sample_parquet_path, faiss_index_path, id_mapping_path]\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing_files:\n",
    "    print(\"❌ Missing required files:\")\n",
    "    for f in missing_files:\n",
    "        print(f\"  - {f}\")\n",
    "    print(\"\\n🔨 Please run these commands first:\")\n",
    "    print(\"  python scripts/create_sample.py\")\n",
    "    print(\"  python scripts/build_local_index.py\")\n",
    "    raise FileNotFoundError(\"Required sample files not found\")\n",
    "\n",
    "# Load data using current architecture\n",
    "print(f\"📊 Loading sample data from: {sample_parquet_path}\")\n",
    "df = pd.read_parquet(sample_parquet_path)\n",
    "\n",
    "print(f\"🔍 Loading FAISS index from: {faiss_index_path}\")\n",
    "faiss_index, id_mapping = load_faiss_index(faiss_index_path, id_mapping_path)\n",
    "\n",
    "print(f\"✅ Data loaded successfully!\")\n",
    "print(f\"  📄 Documents: {len(df)}\")\n",
    "print(f\"  🔍 FAISS vectors: {faiss_index.ntotal}\")\n",
    "print(f\"  🗂️ ID mappings: {len(id_mapping)}\")\n",
    "\n",
    "# Initialize Google Gemini embeddings (current architecture)\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if not google_api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable is required!\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\", \n",
    "    api_key=google_api_key\n",
    ")\n",
    "\n",
    "print(\"🤖 Google Gemini embeddings initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Notebook retriever initialized!\n"
     ]
    }
   ],
   "source": [
    "# Create a simplified local retriever that works with DataFrames (for notebook testing)\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class NotebookLocalRetriever(BaseRetriever):\n",
    "    \"\"\"Simplified local retriever for notebook testing with current architecture.\"\"\"\n",
    "    \n",
    "    embeddings: Any\n",
    "    faiss_index: Any\n",
    "    id_mapping: dict\n",
    "    documents_df: Any\n",
    "    k: int = 5\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self, \n",
    "        query: str, \n",
    "        *, \n",
    "        run_manager: CallbackManagerForRetrieverRun = None\n",
    "    ) -> List[Document]:\n",
    "        print(f\"\\n🔍 [DEBUG] Retrieving for query: '{query}'\")\n",
    "        \n",
    "        # Get query embedding\n",
    "        print(\"🔍 [DEBUG] Getting query embedding...\")\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        query_vector = np.array([query_embedding], dtype='float32')\n",
    "        print(f\"🔍 [DEBUG] Query embedding shape: {query_vector.shape}\")\n",
    "        \n",
    "        # Search FAISS index\n",
    "        print(f\"🔍 [DEBUG] Searching FAISS index for top {self.k} matches...\")\n",
    "        distances, indices = self.faiss_index.search(query_vector, self.k)\n",
    "        print(f\"🔍 [DEBUG] Found indices: {indices[0]}\")\n",
    "        print(f\"🔍 [DEBUG] Distances: {distances[0]}\")\n",
    "        \n",
    "        # Convert to documents\n",
    "        documents = []\n",
    "        print(f\"🔍 [DEBUG] Converting to documents...\")\n",
    "        \n",
    "        for i, idx in enumerate(indices[0]):\n",
    "            if idx in self.id_mapping:\n",
    "                chunk_id = self.id_mapping[idx]\n",
    "                \n",
    "                # Find the row in DataFrame\n",
    "                row = self.documents_df[self.documents_df['chunk_id'] == chunk_id]\n",
    "                if not row.empty:\n",
    "                    text_content = row.iloc[0]['text_chunk']  # Correct column name\n",
    "                    doc_id = row.iloc[0]['doc_id']\n",
    "                    \n",
    "                    print(f\"🔍 [DEBUG] Doc {i+1}: {doc_id} (distance: {distances[0][i]:.4f})\")\n",
    "                    print(f\"🔍 [DEBUG] Text preview: {text_content[:100]}...\")\n",
    "                    \n",
    "                    # Calculate scores (simplified version)\n",
    "                    relevance_score = 1.0 / (1.0 + distances[0][i])\n",
    "                    \n",
    "                    metadata = {\n",
    "                        'chunk_id': chunk_id, \n",
    "                        'doc_id': doc_id, \n",
    "                        'distance': float(distances[0][i]),\n",
    "                        'relevancia': round(relevance_score, 3),\n",
    "                        'final_score': round(relevance_score, 4)\n",
    "                    }\n",
    "                    \n",
    "                    documents.append(Document(\n",
    "                        page_content=text_content,\n",
    "                        metadata=metadata\n",
    "                    ))\n",
    "                    \n",
    "                    # Check if it contains the search term\n",
    "                    search_terms = ['bűnszervezet', 'btk', 'három személy']\n",
    "                    found_terms = [term for term in search_terms if term.lower() in text_content.lower()]\n",
    "                    if found_terms:\n",
    "                        print(f\"🎯 [DEBUG] FOUND relevant terms: {found_terms}\")\n",
    "                    \n",
    "        print(f\"🔍 [DEBUG] Final result: {len(documents)} documents retrieved\")\n",
    "        return documents\n",
    "\n",
    "# Initialize the notebook retriever\n",
    "local_retriever = NotebookLocalRetriever(\n",
    "    embeddings=embeddings,\n",
    "    faiss_index=faiss_index,\n",
    "    id_mapping=id_mapping,\n",
    "    documents_df=df,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(\"✅ Notebook retriever initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing retriever with query: 'Mi a bűnszervezet fogalma a Btk. szerint?'\n",
      "======================================================================\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Mi a bűnszervezet fogalma a Btk. szerint?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [1694 2312 7147 8249 4845]\n",
      "🔍 [DEBUG] Distances: [0.68659014 0.6933098  0.693562   0.695029   0.6973957 ]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: P.20961/2011/3 (distance: 0.6866)\n",
      "🔍 [DEBUG] Text preview: a 2 cég neve Bt.-t képviselte. A cégnek 7 millió 680 ezer forintot fizettek ki, II. r. felperes a pr...\n",
      "🔍 [DEBUG] Doc 2: Bf.11086/2012/6 (distance: 0.6933)\n",
      "🔍 [DEBUG] Text preview: a 2009. június hó 30. napján kelt határozatával rendelte el a vádlott vezetési jogosultságának szüne...\n",
      "🔍 [DEBUG] Doc 3: B.1642/2008/306 (distance: 0.6936)\n",
      "🔍 [DEBUG] Text preview: a ... Bt-nek a tartozást a tulajdonát képező készpénzből, azt alátámasztotta VII.rendű vádlott neve ...\n",
      "🔍 [DEBUG] Doc 4: B.120/2016/21 (distance: 0.6950)\n",
      "🔍 [DEBUG] Text preview: szabadságra bocsátás legkorábbi időpontját a Btk. 38. § (2) bekezdés a) pontja alapján állapította m...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Doc 5: Bf.75/2019/7 (distance: 0.6974)\n",
      "🔍 [DEBUG] Text preview: írtakra terjedhetett ki. E szerint eljárva a másodfokú bíróság megállapította, hogy a Be. 607. § (1)...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "\n",
      "📋 RETRIEVAL RESULTS:\n",
      "Found 5 documents\n",
      "\n",
      "📄 Document 1:\n",
      "  🆔 Doc ID: P.20961/2011/3\n",
      "  📊 Distance: 0.6866\n",
      "  📊 Relevance: 0.593\n",
      "  📝 Text preview: a 2 cég neve Bt.-t képviselte. A cégnek 7 millió 680 ezer forintot fizettek ki, II. r. felperes a projekt tudományos vezetője volt. Közölte, hogy 5 személy a feljelentésében azt is kifogásolta, hogy ....\n",
      "\n",
      "📄 Document 2:\n",
      "  🆔 Doc ID: Bf.11086/2012/6\n",
      "  📊 Distance: 0.6933\n",
      "  📊 Relevance: 0.591\n",
      "  📝 Text preview: a 2009. június hó 30. napján kelt határozatával rendelte el a vádlott vezetési jogosultságának szünetelését, ezért a beszámítást ettől a naptól állapította meg a másodfokú bíróság. A kerületi bíróság ...\n",
      "\n",
      "📄 Document 3:\n",
      "  🆔 Doc ID: B.1642/2008/306\n",
      "  📊 Distance: 0.6936\n",
      "  📊 Relevance: 0.590\n",
      "  📝 Text preview: a ... Bt-nek a tartozást a tulajdonát képező készpénzből, azt alátámasztotta VII.rendű vádlott neve VII.r. és IX.rendű vádlott neve IX.r.vádlottak, valamint 57. sz. tanú vallomása is. A ... Bt. által ...\n",
      "\n",
      "📄 Document 4:\n",
      "  🆔 Doc ID: B.120/2016/21\n",
      "  📊 Distance: 0.6950\n",
      "  📊 Relevance: 0.590\n",
      "  📝 Text preview: szabadságra bocsátás legkorábbi időpontját a Btk. 38. § (2) bekezdés a) pontja alapján állapította meg a bíróság mindkét vádlottnál, K. K. II. r. vádlottnál a végrehajtás utóbbi elrendelése esetére. A...\n",
      "  ✅ Contains 'Btk'!\n",
      "\n",
      "📄 Document 5:\n",
      "  🆔 Doc ID: Bf.75/2019/7\n",
      "  📊 Distance: 0.6974\n",
      "  📊 Relevance: 0.589\n",
      "  📝 Text preview: írtakra terjedhetett ki. E szerint eljárva a másodfokú bíróság megállapította, hogy a Be. 607. § (1) bekezdése, valamint a Be. 608. § (1) bekezdése szerinti - az ítélet hatályon kívül helyezését eredm...\n",
      "  ✅ Contains 'Btk'!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever directly with a legal question\n",
    "test_query = \"Mi a bűnszervezet fogalma a Btk. szerint?\"\n",
    "\n",
    "print(f\"🧪 Testing retriever with query: '{test_query}'\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test retrieval\n",
    "retrieved_docs = local_retriever._get_relevant_documents(test_query)\n",
    "\n",
    "print(f\"\\n📋 RETRIEVAL RESULTS:\")\n",
    "print(f\"Found {len(retrieved_docs)} documents\")\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\n📄 Document {i}:\")\n",
    "    print(f\"  🆔 Doc ID: {doc.metadata['doc_id']}\")\n",
    "    print(f\"  📊 Distance: {doc.metadata['distance']:.4f}\")\n",
    "    print(f\"  📊 Relevance: {doc.metadata['relevancia']:.3f}\")\n",
    "    print(f\"  📝 Text preview: {doc.page_content[:200]}...\")\n",
    "    \n",
    "    # Check for key terms\n",
    "    content_lower = doc.page_content.lower()\n",
    "    if 'bűnszervezet' in content_lower:\n",
    "        print(\"  ✅ Contains 'bűnszervezet'!\")\n",
    "    if 'btk' in content_lower:\n",
    "        print(\"  ✅ Contains 'Btk'!\")\n",
    "    if 'három' in content_lower and 'személy' in content_lower:\n",
    "        print(\"  ✅ Contains 'három személy'!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Building QA chain with current architecture...\n",
      "✅ LLM and prompt loaded!\n",
      "✅ Helper functions ready!\n"
     ]
    }
   ],
   "source": [
    "# Now test the full QA chain with current architecture\n",
    "print(\"🔗 Building QA chain with current architecture...\")\n",
    "\n",
    "# Load prompts (current approach)\n",
    "prompt_path = Path(\"src/prompts/legal_assistant_prompt.txt\")\n",
    "if not prompt_path.exists():\n",
    "    raise FileNotFoundError(f\"Prompt file not found: {prompt_path}\")\n",
    "\n",
    "template = prompt_path.read_text(encoding=\"utf-8\")\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create LLM (current approach)  \n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0,\n",
    "    api_key=SecretStr(google_api_key),\n",
    ")\n",
    "\n",
    "print(\"✅ LLM and prompt loaded!\")\n",
    "\n",
    "# Helper function to format docs (from current qa_chain.py)\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    \"\"\"Format documents for the prompt.\"\"\"\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        chunk_id = doc.metadata.get(\"chunk_id\", \"N/A\")\n",
    "        doc_id = doc.metadata.get(\"doc_id\", \"N/A\")\n",
    "        content = doc.page_content[:500] + \"...\" if len(doc.page_content) > 500 else doc.page_content\n",
    "        \n",
    "        lines.append(f\"### Document ID: {doc_id}\\nContent:\\n{content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "print(\"✅ Helper functions ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Testing complete QA pipeline\n",
      "❓ Query: Milyen büntetés várható kifosztás esetén?\n",
      "======================================================================\n",
      "\n",
      "📖 Step 1: Document Retrieval\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Milyen büntetés várható kifosztás esetén?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [2274 8244  741 3854 1901]\n",
      "🔍 [DEBUG] Distances: [0.65831125 0.66331756 0.6655626  0.67108667 0.6716225 ]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: B.1492/2010/306 (distance: 0.6583)\n",
      "🔍 [DEBUG] Text preview: kolléga 50 milliós letéti pénz jogellenes kifizetési miatt újabb kamarai eljárást is kezdeményezhet ...\n",
      "🔍 [DEBUG] Doc 2: K.21403/2010/19 (distance: 0.6633)\n",
      "🔍 [DEBUG] Text preview: alapján. Ekként a tűzifa értékesítés és a faanyagok beszerzési értékének arányát 1,15-ben számolta e...\n",
      "🔍 [DEBUG] Doc 3: K.700486/2020/23 (distance: 0.6656)\n",
      "🔍 [DEBUG] Text preview: bizonyította, hogy a bányatelken történő kitermelésre a bányakapitányság által jóváhagyott, ellenőrz...\n",
      "🔍 [DEBUG] Doc 4: Gf.40339/2016/5 (distance: 0.6711)\n",
      "🔍 [DEBUG] Text preview: határozták meg azokat a károkat, amelyek bekövetkezése esetére a biztosító kizárta a felelősségét. A...\n",
      "🔍 [DEBUG] Doc 5: P.23729/2008/26 (distance: 0.6716)\n",
      "🔍 [DEBUG] Text preview: számolható el, mely 6 hónapra 117.606.- Ft. A 3 tétel összege 290.490.- Ft, mely a felperest a rendk...\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "Retrieved 5 documents\n",
      "\n",
      "📝 Step 2: Context Formatting\n",
      "Context length: 2734 characters\n",
      "Context preview:\n",
      "### Document ID: B.1492/2010/306\n",
      "Content:\n",
      "kolléga 50 milliós letéti pénz jogellenes kifizetési miatt újabb kamarai eljárást is kezdeményezhet ellene. Ezért személy18 szerint\" ezzel egyidejűleg az öt, a hiányzó ötvenmilliónak a sorsát is le fogjuk papírozni. Mert ez lesz a következő, hogy ott meg eng...\n",
      "\n",
      "🤖 Step 3: LLM Answer Generation\n",
      "\n",
      "✅ FINAL ANSWER:\n",
      "==================================================\n",
      "A megadott dokumentumok alapján a kérdés nem válaszolható meg.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the complete QA pipeline\n",
    "test_query = \"Milyen büntetés várható kifosztás esetén?\"\n",
    "\n",
    "print(f\"🚀 Testing complete QA pipeline\")\n",
    "print(f\"❓ Query: {test_query}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Retrieve documents\n",
    "print(\"\\n📖 Step 1: Document Retrieval\")\n",
    "docs = local_retriever._get_relevant_documents(test_query)\n",
    "print(f\"Retrieved {len(docs)} documents\")\n",
    "\n",
    "# Step 2: Format context\n",
    "print(\"\\n📝 Step 2: Context Formatting\")\n",
    "context = format_docs(docs)\n",
    "print(f\"Context length: {len(context)} characters\")\n",
    "print(f\"Context preview:\\n{context[:300]}...\")\n",
    "\n",
    "# Step 3: Generate answer\n",
    "print(\"\\n🤖 Step 3: LLM Answer Generation\")\n",
    "formatted_input = prompt.format(context=context, question=test_query)\n",
    "\n",
    "try:\n",
    "    result = llm.invoke(formatted_input)\n",
    "    answer = result.content if hasattr(result, 'content') else str(result)\n",
    "    \n",
    "    print(f\"\\n✅ FINAL ANSWER:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(textwrap.fill(answer, width=80))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during LLM invocation: {e}\")\n",
    "    print(\"Context being sent to LLM:\")\n",
    "    print(formatted_input[:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing multiple queries...\n",
      "======================================================================\n",
      "\n",
      "📝 Test 1/5: Mi a bűnszervezet fogalma a Btk. szerint?\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Mi a bűnszervezet fogalma a Btk. szerint?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [1694 2312 7147 8249 4845]\n",
      "🔍 [DEBUG] Distances: [0.68659014 0.6933098  0.693562   0.695029   0.6973957 ]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: P.20961/2011/3 (distance: 0.6866)\n",
      "🔍 [DEBUG] Text preview: a 2 cég neve Bt.-t képviselte. A cégnek 7 millió 680 ezer forintot fizettek ki, II. r. felperes a pr...\n",
      "🔍 [DEBUG] Doc 2: Bf.11086/2012/6 (distance: 0.6933)\n",
      "🔍 [DEBUG] Text preview: a 2009. június hó 30. napján kelt határozatával rendelte el a vádlott vezetési jogosultságának szüne...\n",
      "🔍 [DEBUG] Doc 3: B.1642/2008/306 (distance: 0.6936)\n",
      "🔍 [DEBUG] Text preview: a ... Bt-nek a tartozást a tulajdonát képező készpénzből, azt alátámasztotta VII.rendű vádlott neve ...\n",
      "🔍 [DEBUG] Doc 4: B.120/2016/21 (distance: 0.6950)\n",
      "🔍 [DEBUG] Text preview: szabadságra bocsátás legkorábbi időpontját a Btk. 38. § (2) bekezdés a) pontja alapján állapította m...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Doc 5: Bf.75/2019/7 (distance: 0.6974)\n",
      "🔍 [DEBUG] Text preview: írtakra terjedhetett ki. E szerint eljárva a másodfokú bíróság megállapította, hogy a Be. 607. § (1)...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "  ✅ Best match: P.20961/2011/3 (distance: 0.6866)\n",
      "  📄 Preview: a 2 cég neve Bt.-t képviselte. A cégnek 7 millió 680 ezer forintot fizettek ki, II. r. felperes a projekt tudományos vezetője volt. Közölte, hogy 5 sz...\n",
      "  🎯 Common terms: ['a']\n",
      "--------------------------------------------------\n",
      "\n",
      "📝 Test 2/5: Milyen feltételei vannak a bűnszervezetben való részvételnek?\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Milyen feltételei vannak a bűnszervezetben való részvételnek?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [1542 4372 7971 4563 8116]\n",
      "🔍 [DEBUG] Distances: [0.6318066  0.63695955 0.63862026 0.64223254 0.6429186 ]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: Mf.639295/2011/4 (distance: 0.6318)\n",
      "🔍 [DEBUG] Text preview: az elsőfokú bíróság fellebbezéssel támadott ítéletének a felperes keresetét elutasító részében törté...\n",
      "🔍 [DEBUG] Doc 2: Pf.20344/2019/5 (distance: 0.6370)\n",
      "🔍 [DEBUG] Text preview: a felperessel korábban jó kapcsolatban álló, mára azonban a felperes által bűnözőként beállított ......\n",
      "🔍 [DEBUG] Doc 3: Pf.20172/2019/7 (distance: 0.6386)\n",
      "🔍 [DEBUG] Text preview: között miként osztották meg a GKM rendelet mellékletének C) pontjában felsorolt feladatokat, az egye...\n",
      "🔍 [DEBUG] Doc 4: Bf.186/2023/10 (distance: 0.6422)\n",
      "🔍 [DEBUG] Text preview: Fővárosi Ítélőtábla mint másodfokú bíróság .Bf.186/2023/10. szám Fővárosi Ítélőtábla mint másodfokú ...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Doc 5: B.136/2009/8 (distance: 0.6429)\n",
      "🔍 [DEBUG] Text preview: próbálta rábírni és ennek fejében jogtalan előnyt - egy thaiföldi nyaralást - ígért számukra. A felü...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "  ✅ Best match: Mf.639295/2011/4 (distance: 0.6318)\n",
      "  📄 Preview: az elsőfokú bíróság fellebbezéssel támadott ítéletének a felperes keresetét elutasító részében történő hatályon kívül helyezését, és az elsőfokú bírós...\n",
      "  🎯 Common terms: ['való', 'a']\n",
      "--------------------------------------------------\n",
      "\n",
      "📝 Test 3/5: Mi a különbség az alperes és a felperes között?\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Mi a különbség az alperes és a felperes között?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [5246 1760 4809  328  265]\n",
      "🔍 [DEBUG] Distances: [0.5224251  0.5273427  0.5404826  0.5532989  0.55924684]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: Gfv.30261/2009/6 (distance: 0.5224)\n",
      "🔍 [DEBUG] Text preview: A Legfelsőbb Bíróság egyetért azzal a másodfokú bírósági állásponttal, hogy az I.r. alperest a fuvar...\n",
      "🔍 [DEBUG] Doc 2: Mf.633718/2009/5 (distance: 0.5273)\n",
      "🔍 [DEBUG] Text preview: a Pp. 253. § (2) bekezdése értelmében és a felperes keresetét elutasította. Az alperes fellebbezése ...\n",
      "🔍 [DEBUG] Doc 3: Pf.21465/2014/3 (distance: 0.5405)\n",
      "🔍 [DEBUG] Text preview: megállapítható, hogy a felperes nem a valóságnak megfelelően nyilatkozott a ...t ábrázoló fényképfel...\n",
      "🔍 [DEBUG] Doc 4: Pf.20343/2012/8 (distance: 0.5533)\n",
      "🔍 [DEBUG] Text preview: jutott arra az álláspontra, hogy a felperesi teljesítés az alperes részére ítéleti bizonyossággal ne...\n",
      "🔍 [DEBUG] Doc 5: Pf.20406/2009/6 (distance: 0.5592)\n",
      "🔍 [DEBUG] Text preview: hozta meg a helyes, a felperesi keresetnek helyt adó határozatát, ezért az ítélőtábla a megyei bírós...\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "  ✅ Best match: Gfv.30261/2009/6 (distance: 0.5224)\n",
      "  📄 Preview: A Legfelsőbb Bíróság egyetért azzal a másodfokú bírósági állásponttal, hogy az I.r. alperest a fuvarozó kiválasztásáért, és nem a fuvarozó alkalmazott...\n",
      "  🎯 Common terms: ['a', 'alperes', 'és']\n",
      "--------------------------------------------------\n",
      "\n",
      "📝 Test 4/5: Mikor alkalmazható a feltételes szabadság?\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Mikor alkalmazható a feltételes szabadság?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [7399 3843 6602 3906 5427]\n",
      "🔍 [DEBUG] Distances: [0.6435437  0.6470214  0.6588216  0.66176265 0.6626952 ]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: P.20350/2015/3 (distance: 0.6435)\n",
      "🔍 [DEBUG] Text preview: sőt összeolvadása alappal enged arra következtetni, hogy a felperes ilyen értelemben valóban a pártá...\n",
      "🔍 [DEBUG] Doc 2: G.40032/2018/12 (distance: 0.6470)\n",
      "🔍 [DEBUG] Text preview: érdekeltséget nem alapozza meg. A határozathozatalkor ugyanis azt a szavazó tagot kell kizárni, amel...\n",
      "🔍 [DEBUG] Doc 3: G.21790/2009/17 (distance: 0.6588)\n",
      "🔍 [DEBUG] Text preview: szerzõdést az alperessel, el is készítették a 2008. július 23-án kelt okiratot, nyilatkozatot, amely...\n",
      "🔍 [DEBUG] Doc 4: P.21477/2010/2 (distance: 0.6618)\n",
      "🔍 [DEBUG] Text preview: Fejér Megyei Bíróság 27.P.21.477/2010/15.szám A MAGYAR KÖZTÁRSASÁG NEVÉBEN! A Fejér Megyei Bíróság a...\n",
      "🔍 [DEBUG] Doc 5: Mfv.10096/2022/6 (distance: 0.6627)\n",
      "🔍 [DEBUG] Text preview: A Kúria felülvizsgálati bíróság í t é l e t e ügy száma: Mfv.VIII.10.096/2022/6. tanács tagjai: Dr. ...\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "  ✅ Best match: P.20350/2015/3 (distance: 0.6435)\n",
      "  📄 Preview: sőt összeolvadása alappal enged arra következtetni, hogy a felperes ilyen értelemben valóban a pártállam erőszakszervezetének a része volt. Ebből az á...\n",
      "  🎯 Common terms: ['a']\n",
      "--------------------------------------------------\n",
      "\n",
      "📝 Test 5/5: Mit jelent a bizonyítási teher?\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Mit jelent a bizonyítási teher?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [3854 4091  741 6740 2930]\n",
      "🔍 [DEBUG] Distances: [0.6219102  0.6607754  0.666665   0.66877663 0.6773427 ]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: Gf.40339/2016/5 (distance: 0.6219)\n",
      "🔍 [DEBUG] Text preview: határozták meg azokat a károkat, amelyek bekövetkezése esetére a biztosító kizárta a felelősségét. A...\n",
      "🔍 [DEBUG] Doc 2: Pf.21073/2013/7 (distance: 0.6608)\n",
      "🔍 [DEBUG] Text preview: meg az új élethelyzethez történő alkalmazkodása során. A káresemény bekövetkezésekor irányadó értékv...\n",
      "🔍 [DEBUG] Doc 3: K.700486/2020/23 (distance: 0.6667)\n",
      "🔍 [DEBUG] Text preview: bizonyította, hogy a bányatelken történő kitermelésre a bányakapitányság által jóváhagyott, ellenőrz...\n",
      "🔍 [DEBUG] Doc 4: P.20809/2005/47 (distance: 0.6688)\n",
      "🔍 [DEBUG] Text preview: karrierje és a fenti évek alatt szerzett vagyongyarapodása biztonságban maradjon. Állította továbbá,...\n",
      "🔍 [DEBUG] Doc 5: K.30793/2008/4 (distance: 0.6773)\n",
      "🔍 [DEBUG] Text preview: szerint - mely az alperesi hatóságéval teljes mértékben megegyezik - a menekültügyi hatóság (bizonyí...\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "  ✅ Best match: Gf.40339/2016/5 (distance: 0.6219)\n",
      "  📄 Preview: határozták meg azokat a károkat, amelyek bekövetkezése esetére a biztosító kizárta a felelősségét. Az alperes a 4. könyv 4. §-ában a kármegelőzési köt...\n",
      "  🎯 Common terms: ['bizonyítási', 'a']\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Multi-query testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple queries to verify functionality\n",
    "test_queries = [\n",
    "    \"Mi a bűnszervezet fogalma a Btk. szerint?\",\n",
    "    \"Milyen feltételei vannak a bűnszervezetben való részvételnek?\",\n",
    "    \"Mi a különbség az alperes és a felperes között?\",\n",
    "    \"Mikor alkalmazható a feltételes szabadság?\",\n",
    "    \"Mit jelent a bizonyítási teher?\"\n",
    "]\n",
    "\n",
    "print(\"🧪 Testing multiple queries...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n📝 Test {i}/5: {query}\")\n",
    "    \n",
    "    # Quick retrieval test\n",
    "    docs = local_retriever._get_relevant_documents(query)\n",
    "    \n",
    "    if docs:\n",
    "        best_doc = docs[0]\n",
    "        doc_id = best_doc.metadata.get('doc_id', 'N/A')\n",
    "        distance = best_doc.metadata.get('distance', 'N/A')\n",
    "        \n",
    "        print(f\"  ✅ Best match: {doc_id} (distance: {distance:.4f})\")\n",
    "        print(f\"  📄 Preview: {best_doc.page_content[:150]}...\")\n",
    "        \n",
    "        # Check relevance\n",
    "        query_words = query.lower().split()\n",
    "        content_words = best_doc.page_content.lower().split()\n",
    "        common_words = set(query_words) & set(content_words)\n",
    "        if common_words:\n",
    "            print(f\"  🎯 Common terms: {list(common_words)[:3]}\")\n",
    "    else:\n",
    "        print(f\"  ❌ No documents found\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n✅ Multi-query testing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "📄 Sample dataset size: 8293 documents\n",
      "🔍 FAISS index size: 8293 vectors\n",
      "🗂️ ID mapping entries: 8293\n",
      "\n",
      "🔍 Sample ID mappings:\n",
      "  FAISS[0] -> P.20693/2011/64-2\n",
      "  FAISS[1] -> Pf.20055/2020/5-2\n",
      "  FAISS[2] -> B.101/2021/25-1\n",
      "\n",
      "📊 Document statistics:\n",
      "  Unique documents: 8030\n",
      "  Avg chunks per doc: 1.0\n",
      "  Avg text length: 6961 chars\n",
      "  Min text length: 213 chars\n",
      "  Max text length: 8000 chars\n",
      "\n",
      "🤖 Model configuration:\n",
      "  Embeddings: models/text-embedding-004\n",
      "  LLM: models/gemini-2.5-pro\n",
      "  Temperature: 0.0\n",
      "\n",
      "✅ Notebook testing setup complete!\n",
      "🎯 Ready for production-like RAG testing!\n"
     ]
    }
   ],
   "source": [
    "# Performance and debugging summary\n",
    "print(\"📊 PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"📄 Sample dataset size: {len(df)} documents\")\n",
    "print(f\"🔍 FAISS index size: {faiss_index.ntotal} vectors\")\n",
    "print(f\"🗂️ ID mapping entries: {len(id_mapping)}\")\n",
    "\n",
    "# Check first few mappings\n",
    "print(f\"\\n🔍 Sample ID mappings:\")\n",
    "for i, (faiss_idx, chunk_id) in enumerate(list(id_mapping.items())[:3]):\n",
    "    print(f\"  FAISS[{faiss_idx}] -> {chunk_id}\")\n",
    "\n",
    "# Check document distribution\n",
    "print(f\"\\n📊 Document statistics:\")\n",
    "if 'doc_id' in df.columns:\n",
    "    unique_docs = df['doc_id'].nunique()\n",
    "    print(f\"  Unique documents: {unique_docs}\")\n",
    "    print(f\"  Avg chunks per doc: {len(df) / unique_docs:.1f}\")\n",
    "\n",
    "if 'text_chunk' in df.columns:\n",
    "    text_lengths = df['text_chunk'].str.len()\n",
    "    print(f\"  Avg text length: {text_lengths.mean():.0f} chars\")\n",
    "    print(f\"  Min text length: {text_lengths.min()} chars\")\n",
    "    print(f\"  Max text length: {text_lengths.max()} chars\")\n",
    "\n",
    "print(f\"\\n🤖 Model configuration:\")\n",
    "print(f\"  Embeddings: {embeddings.model}\")\n",
    "print(f\"  LLM: {llm.model}\")\n",
    "print(f\"  Temperature: {llm.temperature}\")\n",
    "\n",
    "print(f\"\\n✅ Notebook testing setup complete!\")\n",
    "print(f\"🎯 Ready for production-like RAG testing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Optional: Testing with simplified reranking...\n",
      "\n",
      "🔍 [DEBUG] Retrieving for query: 'Mi a bűnszervezet fogalma a Btk. szerint?'\n",
      "🔍 [DEBUG] Getting query embedding...\n",
      "🔍 [DEBUG] Query embedding shape: (1, 768)\n",
      "🔍 [DEBUG] Searching FAISS index for top 5 matches...\n",
      "🔍 [DEBUG] Found indices: [1694 2312 7147 8249 4845]\n",
      "🔍 [DEBUG] Distances: [0.68659014 0.6933098  0.693562   0.695029   0.6973957 ]\n",
      "🔍 [DEBUG] Converting to documents...\n",
      "🔍 [DEBUG] Doc 1: P.20961/2011/3 (distance: 0.6866)\n",
      "🔍 [DEBUG] Text preview: a 2 cég neve Bt.-t képviselte. A cégnek 7 millió 680 ezer forintot fizettek ki, II. r. felperes a pr...\n",
      "🔍 [DEBUG] Doc 2: Bf.11086/2012/6 (distance: 0.6933)\n",
      "🔍 [DEBUG] Text preview: a 2009. június hó 30. napján kelt határozatával rendelte el a vádlott vezetési jogosultságának szüne...\n",
      "🔍 [DEBUG] Doc 3: B.1642/2008/306 (distance: 0.6936)\n",
      "🔍 [DEBUG] Text preview: a ... Bt-nek a tartozást a tulajdonát képező készpénzből, azt alátámasztotta VII.rendű vádlott neve ...\n",
      "🔍 [DEBUG] Doc 4: B.120/2016/21 (distance: 0.6950)\n",
      "🔍 [DEBUG] Text preview: szabadságra bocsátás legkorábbi időpontját a Btk. 38. § (2) bekezdés a) pontja alapján állapította m...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Doc 5: Bf.75/2019/7 (distance: 0.6974)\n",
      "🔍 [DEBUG] Text preview: írtakra terjedhetett ki. E szerint eljárva a másodfokú bíróság megállapította, hogy a Be. 607. § (1)...\n",
      "🎯 [DEBUG] FOUND relevant terms: ['btk']\n",
      "🔍 [DEBUG] Final result: 5 documents retrieved\n",
      "📋 Before reranking: 5 docs\n",
      "📋 After reranking: 3 docs\n",
      "\n",
      "🏆 Rank 1:\n",
      "  Doc ID: Bf.75/2019/7\n",
      "  Original score: 0.5889999866485596\n",
      "  Reranker score: 1.1890000104904175\n",
      "  Text: írtakra terjedhetett ki. E szerint eljárva a másodfokú bíróság megállapította, hogy a Be. 607. § (1)...\n",
      "\n",
      "🏆 Rank 2:\n",
      "  Doc ID: B.120/2016/21\n",
      "  Original score: 0.5899999737739563\n",
      "  Reranker score: 1.090000033378601\n",
      "  Text: szabadságra bocsátás legkorábbi időpontját a Btk. 38. § (2) bekezdés a) pontja alapján állapította m...\n",
      "\n",
      "🏆 Rank 3:\n",
      "  Doc ID: P.20961/2011/3\n",
      "  Original score: 0.5929999947547913\n",
      "  Reranker score: 0.8930000066757202\n",
      "  Text: a 2 cég neve Bt.-t képviselte. A cégnek 7 millió 680 ezer forintot fizettek ki, II. r. felperes a pr...\n",
      "\n",
      "✅ Simplified reranking test completed!\n"
     ]
    }
   ],
   "source": [
    "# Optional: Test with simplified reranking\n",
    "print(\"🔄 Optional: Testing with simplified reranking...\")\n",
    "\n",
    "def simple_rerank_by_keyword_boost(docs: List[Document], query: str, top_k: int = 3) -> List[Document]:\n",
    "    \"\"\"Simplified reranking based on keyword matching and distance.\"\"\"\n",
    "    \n",
    "    # Extract key terms from query\n",
    "    query_terms = set(query.lower().split())\n",
    "    \n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        base_score = doc.metadata.get('relevancia', 0)\n",
    "        \n",
    "        # Keyword boost\n",
    "        content_lower = doc.page_content.lower()\n",
    "        term_matches = sum(1 for term in query_terms if term in content_lower)\n",
    "        keyword_boost = term_matches * 0.1\n",
    "        \n",
    "        # Special legal term boost\n",
    "        legal_boost = 0\n",
    "        if 'btk' in content_lower:\n",
    "            legal_boost += 0.2\n",
    "        if 'bűnszervezet' in content_lower:\n",
    "            legal_boost += 0.3\n",
    "        if 'törvény' in content_lower:\n",
    "            legal_boost += 0.1\n",
    "            \n",
    "        final_score = base_score + keyword_boost + legal_boost\n",
    "        doc.metadata['reranker_score'] = round(final_score, 4)\n",
    "        scored_docs.append(doc)\n",
    "    \n",
    "    # Sort by final score\n",
    "    scored_docs.sort(key=lambda d: d.metadata['reranker_score'], reverse=True)\n",
    "    return scored_docs[:top_k]\n",
    "\n",
    "# Test reranking\n",
    "query = \"Mi a bűnszervezet fogalma a Btk. szerint?\"\n",
    "docs = local_retriever._get_relevant_documents(query)\n",
    "\n",
    "print(f\"📋 Before reranking: {len(docs)} docs\")\n",
    "reranked_docs = simple_rerank_by_keyword_boost(docs, query, top_k=3)\n",
    "\n",
    "print(f\"📋 After reranking: {len(reranked_docs)} docs\")\n",
    "for i, doc in enumerate(reranked_docs, 1):\n",
    "    print(f\"\\n🏆 Rank {i}:\")\n",
    "    print(f\"  Doc ID: {doc.metadata['doc_id']}\")\n",
    "    print(f\"  Original score: {doc.metadata['relevancia']}\")\n",
    "    print(f\"  Reranker score: {doc.metadata['reranker_score']}\")\n",
    "    print(f\"  Text: {doc.page_content[:100]}...\")\n",
    "\n",
    "print(\"\\n✅ Simplified reranking test completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
